apiVersion: apps/v1
kind: Deployment
metadata:
  name: memory-hog-deployment
  labels:
    app: memory-hog
spec:
  replicas: 2  # Nombre élevé de réplicas pour garantir l'épuisement
  selector:
    matchLabels:
      app: memory-hog
  template:
    metadata:
      labels:
        app: memory-hog
    spec:
      containers:
      - name: memory-consumer
        image: gcr.io/google-containers/busybox:latest
        command: ["/bin/sh", "-c"]
        args:
          - |
            echo "Début de l'allocation mémoire intensive..."
            
            # Afficher la mémoire disponible au démarrage
            free -m
            
            # Allouer de la mémoire et la maintenir allouée
            memory_allocation() {
              local target_mb=$1
              local allocated=0
              local chunk_size=50  # MB par itération
              
              # Tableau pour conserver les données en mémoire
              data_chunks=()
              
              while [ $allocated -lt $target_mb ]; do
                # Générer des données aléatoires qui ne peuvent pas être compressées
                chunk=$(head -c ${chunk_size}M /dev/urandom | base64)
                data_chunks+=("$chunk")
                
                allocated=$((allocated + chunk_size))
                
                if [ $((allocated % 100)) -eq 0 ]; then
                  echo "Mémoire allouée jusqu'à présent: $allocated MB"
                  free -m
                fi
                
                # Pause courte pour ne pas surcharger instantanément le système
                sleep 0.5
              done
              
              echo "Allocation de $allocated MB complète!"
              
              # Maintenir l'allocation active en accédant périodiquement aux données
              while true; do
                for i in "${!data_chunks[@]}"; do
                  # Accéder aux données pour s'assurer qu'elles restent en mémoire
                  echo "${#data_chunks[$i]}" > /dev/null
                done
                sleep 10
                echo "Mémoire maintenue à $allocated MB - $(date)"
                free -m
              done
            }
            
            # En fonction de l'ID du pod, allouer différentes quantités de mémoire
            POD_NAME=$(hostname)
            POD_ID=$(echo $POD_NAME | grep -o '[0-9]*$')
            
            case $((POD_ID % 5)) in
              0)
                echo "Ce pod ($POD_NAME) va allouer 400 MB"
                memory_allocation 400
                ;;
              1)
                echo "Ce pod ($POD_NAME) va allouer 300 MB"
                memory_allocation 300
                ;;
              2)
                echo "Ce pod ($POD_NAME) va allouer 250 MB"
                memory_allocation 250
                ;;
              3)
                echo "Ce pod ($POD_NAME) va allouer 200 MB"
                memory_allocation 200
                ;;
              4)
                echo "Ce pod ($POD_NAME) va allouer 350 MB"
                memory_allocation 350
                ;;
            esac
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
          limits:
            memory: "500Mi"
            cpu: "200m"
---
# Un deuxième déploiement avec une stratégie d'allocation différente
apiVersion: apps/v1
kind: Deployment
metadata:
  name: memory-hog-malloc
  labels:
    app: memory-hog-malloc
spec:
  replicas: 2
  selector:
    matchLabels:
      app: memory-hog-malloc
  template:
    metadata:
      labels:
        app: memory-hog-malloc
    spec:
      containers:
      - name: memory-malloc
        image: gcr.io/google-containers/busybox:latest
        command: ["/bin/sh", "-c"]
        args:
          - |
            echo "Démarrage de l'allocation mémoire via tmpfs..."
            
            # Monter un tmpfs
            mkdir -p /mnt/tmpfs-hog
            mount -t tmpfs -o size=400M tmpfs /mnt/tmpfs-hog
            
            # Remplir le tmpfs avec des fichiers aléatoires
            cd /mnt/tmpfs-hog
            
            # Créer plusieurs fichiers pour remplir le tmpfs
            for i in $(seq 1 8); do
              echo "Création du fichier $i de 50 MB..."
              dd if=/dev/urandom of=file_$i bs=1M count=50
            done
            
            # Vérifier l'espace utilisé
            df -h /mnt/tmpfs-hog
            
            # Maintenir les fichiers en mémoire
            echo "Maintien des données en mémoire..."
            while true; do
              # Lire périodiquement les fichiers pour s'assurer qu'ils restent en mémoire
              for i in $(seq 1 8); do
                cat file_$i > /dev/null
              done
              sleep 10
              echo "Mémoire tmpfs maintenue - $(date)"
              df -h /mnt/tmpfs-hog
              free -m
            done
        securityContext:
          privileged: true  # Nécessaire pour monter tmpfs
        resources:
          requests:
            memory: "200Mi"
            cpu: "100m"
          limits:
            memory: "500Mi"
            cpu: "200m"
---
# Un troisième déploiement utilisant une boucle fork-bomb contrôlée
apiVersion: apps/v1
kind: Deployment
metadata:
  name: memory-hog-processes
  labels:
    app: memory-hog-processes
spec:
  replicas: 3
  selector:
    matchLabels:
      app: memory-hog-processes
  template:
    metadata:
      labels:
        app: memory-hog-processes
    spec:
      containers:
      - name: process-spawner
        image: gcr.io/google-containers/busybox:latest
        command: ["/bin/sh", "-c"]
        args:
          - |
            echo "Démarrage de la consommation mémoire par processus multiples..."
            
            # Fonction pour créer plusieurs processus qui consomment de la mémoire
            controlled_process_spawn() {
              local num_processes=$1
              local mem_per_process=$2  # en MB
              
              echo "Création de $num_processes processus consommant chacun $mem_per_process MB..."
              
              for i in $(seq 1 $num_processes); do
                # Démarrer un processus fils qui alloue de la mémoire
                (
                  # Allouer la mémoire spécifiée
                  memory_chunk=$(head -c ${mem_per_process}M /dev/urandom | base64)
                  
                  # Boucle infinie pour maintenir le processus actif
                  while true; do
                    # Toucher aux données pour qu'elles restent en mémoire
                    echo "${#memory_chunk}" > /dev/null
                    sleep 5
                  done
                ) &
                
                # Stocker le PID pour pouvoir le gérer plus tard
                echo "Processus $i démarré avec PID $!"
                
                # Pause pour étaler la création des processus
                sleep 1
              done
              
              # Attendre indéfiniment, en maintenant les processus fils actifs
              wait
            }
            
            # Démarrer la création de processus
            # Créer 10 processus avec 30 MB chacun = ~300 MB total
            controlled_process_spawn 10 30
        resources:
          requests:
            memory: "150Mi"
            cpu: "100m"
          limits:
            memory: "400Mi"
            cpu: "200m"
---
# Un quatrième déploiement avec des JOB en parallèle
apiVersion: apps/v1
kind: Deployment
metadata:
  name: memory-hog-loops
  labels:
    app: memory-hog-loops
spec:
  replicas: 2
  selector:
    matchLabels:
      app: memory-hog-loops
  template:
    metadata:
      labels:
        app: memory-hog-loops
    spec:
      containers:
      - name: memory-loops
        image: gcr.io/google-containers/busybox:latest
        command: ["/bin/sh", "-c"]
        args:
          - |
            echo "Démarrage de la consommation mémoire par boucles de calcul..."
            
            # Fonction qui fait des calculs intensifs en mémoire
            memory_intensive_loop() {
              local size_mb=$1
              local iterations=$2
              
              echo "Démarrage de la boucle avec taille $size_mb MB pour $iterations itérations"
              
              for iter in $(seq 1 $iterations); do
                # Générer une grande chaîne aléatoire
                big_data=$(head -c ${size_mb}M /dev/urandom | base64)
                
                # Faire quelques opérations sur les données
                for op in $(seq 1 5); do
                  result="${big_data}${big_data:0:1000}"
                  big_data="${result}${big_data:1000:2000}"
                done
                
                echo "Itération $iter terminée, taille des données: ${#big_data} caractères"
                
                sleep 1
              done
            }
            
            # Exécuter plusieurs boucles en parallèle
            memory_intensive_loop 100 999999 &
            memory_intensive_loop 50 999999 &
            memory_intensive_loop 75 999999 &
            
            # Attendre que toutes les boucles se terminent (ce qui ne devrait jamais arriver)
            wait
        resources:
          requests:
            memory: "200Mi"
            cpu: "200m"
          limits:
            memory: "400Mi"
            cpu: "300m"
